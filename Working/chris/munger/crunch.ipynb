{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file locations\n",
    "data_dir      = \"data-black-friday\"\n",
    "src_dir       = \"{}/src\".format(data_dir)\n",
    "report_dir    = \"{}/report\".format(data_dir)\n",
    "clean_dir     = \"{}/clean\".format(data_dir)\n",
    "\n",
    "# Raw data file(s)\n",
    "csv_files = {\"2011\":\"deals.20111124.csv\",\n",
    "             \"2012\":\"deals.20121121.csv\",\n",
    "             \"2013\":\"deals.20131127.csv\",\n",
    "             \"2014\":\"deals.20141127.csv\",\n",
    "             \"2015\":\"deals.20151126.csv\",\n",
    "             \"2016\":\"deals.20161124.csv\",\n",
    "             \"2017\":\"deals.20171123.csv\",\n",
    "             \"store-names\":\"bfa.store.names.csv\",\n",
    "             \"store-category\":\"bfa.store.category.csv\",\n",
    "             \"sanitized\":\"bfa.csv\",\n",
    "             \"san-2011\":\"bfa.2011.csv\",\n",
    "             \"san-2012\":\"bfa.2012.csv\",\n",
    "             \"san-2013\":\"bfa.2013.csv\",\n",
    "             \"san-2014\":\"bfa.2014.csv\",\n",
    "             \"san-2015\":\"bfa.2015.csv\",\n",
    "             \"san-2016\":\"bfa.2016.csv\",\n",
    "             \"san-2017\":\"bfa.2017.csv\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## Functions\n",
    "-------------------------------------------------\n",
    "'''\n",
    "def now():\n",
    "    return str(datetime.datetime.now())\n",
    "\n",
    "def path_source(filename):\n",
    "    result = \"{}/{}\".format(src_dir, filename)\n",
    "    return result\n",
    "\n",
    "def path_clean(filename):\n",
    "    result = \"{}/{}\".format(clean_dir, filename)\n",
    "    return result\n",
    "\n",
    "def path_report(filename):\n",
    "    result = \"{}/{}\".format(report_dir, filename)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read in the goods -- raw source data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2011 = pd.read_csv(path_source(csv_files[\"2011\"]), names=['Store','Category','Item','Price'])\n",
    "df2012 = pd.read_csv(path_source(csv_files[\"2012\"]))\n",
    "df2013 = pd.read_csv(path_source(csv_files[\"2013\"]))\n",
    "df2014 = pd.read_csv(path_source(csv_files[\"2014\"]))\n",
    "df2015 = pd.read_csv(path_source(csv_files[\"2015\"]))\n",
    "df2016 = pd.read_csv(path_source(csv_files[\"2016\"]))\n",
    "df2017 = pd.read_csv(path_source(csv_files[\"2017\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- drop data that is not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2012.drop(columns=['Early Bird','Rebate'], inplace=True)\n",
    "df2013.drop(columns=['Early Bird','Rebate'], inplace=True)\n",
    "df2014.drop(columns=['Early Bird','Rebate','URL'], inplace=True)\n",
    "df2015.drop(columns=['Early Bird','Rebate','URL'], inplace=True)\n",
    "df2016.drop(columns=['URL'], inplace=True)\n",
    "df2017.drop(columns=['Original or Current Price','URL'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2017.rename(columns = {'Sale Price':'Price'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2011['SubCategory'] = '';\n",
    "df2012['SubCategory'] = '';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- break apart into to category columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2017['Category'], df2017['SubCategory'] = df2017['Category'].str.split(' >> ', 1).str\n",
    "df2016['Category'], df2016['SubCategory'] = df2016['Category'].str.split(' >> ', 1).str\n",
    "df2015['Category'], df2015['SubCategory'] = df2015['Category'].str.split(' >> ', 1).str\n",
    "df2014['Category'], df2014['SubCategory'] = df2014['Category'].str.split(' >> ', 1).str\n",
    "df2013['Category'], df2013['SubCategory'] = df2013['Category'].str.split(' >> ', 1).str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2013['Category'], df2013['SubCategory'] = df2013['Category'].str.split(' > ', 1).str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- remove $ from price; convert to number and in process return NaN for non-numeric entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2017['Price'] = pd.to_numeric(df2017['Price'].replace('[\\$,]', '', regex=True),  errors='coerce')\n",
    "df2016['Price'] = pd.to_numeric(df2016['Price'].replace('[\\$,]', '', regex=True),  errors='coerce')\n",
    "df2015['Price'] = pd.to_numeric(df2015['Price'].replace('[\\$,]', '', regex=True),  errors='coerce')\n",
    "df2014['Price'] = pd.to_numeric(df2014['Price'].replace('[\\$,]', '', regex=True),  errors='coerce')\n",
    "df2013['Price'] = pd.to_numeric(df2013['Price'].replace('[\\$,]', '', regex=True),  errors='coerce')\n",
    "df2012['Price'] = pd.to_numeric(df2012['Price'].replace('[\\$,]', '', regex=True),  errors='coerce')\n",
    "df2011['Price'] = pd.to_numeric(df2011['Price'].replace('[\\$,]', '', regex=True),  errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- drop NaN rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2017 = df2017[df2017['Price'].notnull()]\n",
    "df2016 = df2016[df2016['Price'].notnull()]\n",
    "df2015 = df2015[df2015['Price'].notnull()]\n",
    "df2014 = df2014[df2014['Price'].notnull()]\n",
    "df2013 = df2013[df2013['Price'].notnull()]\n",
    "df2012 = df2012[df2012['Price'].notnull()]\n",
    "df2011 = df2011[df2011['Price'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- upper case the store name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2011['Store'] = df2011['Store'].str.upper()\n",
    "df2012['Store'] = df2012['Store'].str.upper()\n",
    "df2013['Store'] = df2013['Store'].str.upper()\n",
    "df2014['Store'] = df2014['Store'].str.upper()\n",
    "df2015['Store'] = df2015['Store'].str.upper()\n",
    "df2016['Store'] = df2016['Store'].str.upper()\n",
    "df2017['Store'] = df2017['Store'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- append year column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2011['Year'] = 2011\n",
    "df2012['Year'] = 2012\n",
    "df2013['Year'] = 2013\n",
    "df2014['Year'] = 2014\n",
    "df2015['Year'] = 2015\n",
    "df2016['Year'] = 2016\n",
    "df2017['Year'] = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare DataFreames for CSV output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'clean' dataframe for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr2011 = df2011[['Year', 'Store', 'Category', 'SubCategory', 'Item', 'Price']]\n",
    "yr2012 = df2012[['Year', 'Store', 'Category', 'SubCategory', 'Item', 'Price']]\n",
    "yr2013 = df2013[['Year', 'Store', 'Category', 'SubCategory', 'Item', 'Price']]\n",
    "yr2014 = df2014[['Year', 'Store', 'Category', 'SubCategory', 'Item', 'Price']]\n",
    "yr2015 = df2015[['Year', 'Store', 'Category', 'SubCategory', 'Item', 'Price']]\n",
    "yr2016 = df2016[['Year', 'Store', 'Category', 'SubCategory', 'Item', 'Price']]\n",
    "yr2017 = df2017[['Year', 'Store', 'Category', 'SubCategory', 'Item', 'Price']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- package all the good in together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitized_df = pd.DataFrame(pd.concat([yr2011, yr2012, yr2013, yr2014, yr2015, yr2016, yr2017]))\n",
    "sanitized_df = sanitized_df.sort_values(['Year', 'Store']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get unique store names and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_Names_df = pd.DataFrame(pd.concat([df2011['Store'].drop_duplicates(),\n",
    "                               df2012['Store'].drop_duplicates(),\n",
    "                               df2013['Store'].drop_duplicates(),\n",
    "                               df2014['Store'].drop_duplicates(),                              \n",
    "                               df2015['Store'].drop_duplicates(),\n",
    "                               df2016['Store'].drop_duplicates(),\n",
    "                               df2017['Store'].drop_duplicates()]))\n",
    "\n",
    "store_Names_df = store_Names_df.drop_duplicates()\n",
    "store_Names_df = store_Names_df.rename(columns = {'Store':'name'}).sort_values('name').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_Category_df = pd.DataFrame(pd.concat([df2011['Category'].drop_duplicates(),\n",
    "                               df2012['Category'].drop_duplicates(),\n",
    "                               df2013['Category'].drop_duplicates(),\n",
    "                               df2014['Category'].drop_duplicates(),                              \n",
    "                               df2015['Category'].drop_duplicates(),\n",
    "                               df2016['Category'].drop_duplicates(),\n",
    "                               df2017['Category'].drop_duplicates()]))\n",
    "\n",
    "store_Category_df = store_Category_df.drop_duplicates().sort_values('Category').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_Names_df.to_csv(path_report(csv_files[\"store-names\"]), index=False)\n",
    "store_Category_df.to_csv(path_report(csv_files[\"store-category\"]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr2011.to_csv(path_clean(csv_files[\"san-2011\"]), index=False)\n",
    "yr2012.to_csv(path_clean(csv_files[\"san-2012\"]), index=False)\n",
    "yr2013.to_csv(path_clean(csv_files[\"san-2013\"]), index=False)\n",
    "yr2014.to_csv(path_clean(csv_files[\"san-2014\"]), index=False)\n",
    "yr2015.to_csv(path_clean(csv_files[\"san-2015\"]), index=False)\n",
    "yr2016.to_csv(path_clean(csv_files[\"san-2016\"]), index=False)\n",
    "yr2017.to_csv(path_clean(csv_files[\"san-2017\"]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanitized_df.to_csv(path_clean(csv_files[\"sanitized\"]), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
